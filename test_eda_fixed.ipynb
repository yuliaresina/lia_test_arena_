{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f010dea6",
      "metadata": {},
      "source": [
        "# **Priliminary data analysis of Arena HUBs**\n",
        "\n",
        "## Data are the logs from a remote Arena system, access control system that unlocks doors.\n",
        "\n",
        "Initial files contain the following records:\n",
        "\n",
        "*_id –  record ID\n",
        "\n",
        "_uuid – device identifier, from hardware ( IMEI-like value).\n",
        "\n",
        "_timestamp – event time (UTC)\n",
        "\n",
        "rpc – the type of action/event (always “unlock” in the file).\n",
        "\n",
        "_ack_timestamp – acknowledgement time (when the system confirmed the event).\n",
        "\n",
        "_ack_status – acknowledgement result (0 means success, empty means not acknowledged).*\n",
        "\n",
        "Initial second dataset contain diagnostic telemetry and metadata \n",
        "It’s recording resets, uptime, firmware versions, and network signal strength.\n",
        "\n",
        "*_id – unique row identifier \n",
        "\n",
        "_uuid – device identifier \n",
        "\n",
        "timestamp – when the record was captured\n",
        "\n",
        "just_booted – t means the device had just restarted when the log was recorded.\n",
        "\n",
        "reset_reason – numeric code for why the device reset (e.g., 0, 2, 16 … probably mapped to watchdog, power cycle, etc.).\n",
        "\n",
        "uptime – how many seconds the device had been running before the log.\n",
        "\n",
        "fw_version – firmware version running on the device.\n",
        "\n",
        "modem_fw_version – modem firmware version \n",
        "\n",
        "rsrp – signal strength (Reference Signal Received Power, typical for LTE/5G modules).\n",
        "*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ea90c4ed",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load Excel\n",
        "df = pd.read_excel(\"Enhets data.xlsx\")\n",
        "\n",
        "# Combine date + time into a single datetime column\n",
        "df['timestamp'] = pd.to_datetime(\n",
        "    df['date'].astype(str) + \" \" + df['time'].astype(str),\n",
        "    errors='coerce'\n",
        ")\n",
        "\n",
        "# Keep only the combined column\n",
        "df = df[['timestamp']]\n",
        "\n",
        "# Save to CSV\n",
        "df.to_csv(\"enhets_datetime.csv\", index=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "1598d441",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1045, 1)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv (\"enhets_datetime.csv\")\n",
        "df.head()\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "8f5c4b91",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved as: Enhets data - Katarinasstädtjänst Enhet Grind - RSRP_corr.csv\n",
            "Saved as: Enhets data - SMRTEC huvudEntre - RSRP.csv_corr.csv\n",
            "Saved as: Enhets data - Varbergs boxningsklubb - RSRP.csv_corr.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your CSV\n",
        "file_path = \"Enhets data - Katarinasstädtjänst Enhet Grind - RSRP.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Replace 'date' column with merged datetime\n",
        "df['date'] = pd.to_datetime(\n",
        "    df['date'].astype(str) + \" \" + df['time'].astype(str),\n",
        "    errors='coerce'\n",
        ")\n",
        "\n",
        "# Drop the separate 'time' column\n",
        "df = df.drop(columns=['time'])\n",
        "\n",
        "# Optionally rename 'date' → 'datetime'\n",
        "df = df.rename(columns={'date': 'timestamp'})\n",
        "\n",
        "# Save to new CSV\n",
        "output_file = \"Enhets data - Katarinasstädtjänst Enhet Grind - RSRP_corr.csv\"\n",
        "df.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"Saved as: {output_file}\")\n",
        "\n",
        "# Load your CSV\n",
        "file_path = \"Enhets data - SMRTEC huvudEntre - RSRP.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Replace 'date' column with merged datetime\n",
        "df['date'] = pd.to_datetime(\n",
        "    df['date'].astype(str) + \" \" + df['time'].astype(str),\n",
        "    errors='coerce'\n",
        ")\n",
        "\n",
        "# Drop the separate 'time' column\n",
        "df = df.drop(columns=['time'])\n",
        "\n",
        "# Optionally rename 'date' → 'datetime'\n",
        "df = df.rename(columns={'date': 'timestamp'})\n",
        "\n",
        "# Save to new CSV\n",
        "output_file = \"Enhets data - SMRTEC huvudEntre - RSRP.csv_corr.csv\"\n",
        "df.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"Saved as: {output_file}\")\n",
        "\n",
        "# Load your CSV\n",
        "file_path = \"Enhets data - Varbergs boxningsklubb - RSRP.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Replace 'date' column with merged datetime\n",
        "df['date'] = pd.to_datetime(\n",
        "    df['date'].astype(str) + \" \" + df['time'].astype(str),\n",
        "    errors='coerce'\n",
        ")\n",
        "\n",
        "# Drop the separate 'time' column\n",
        "df = df.drop(columns=['time'])\n",
        "\n",
        "# Optionally rename 'date' → 'datetime'\n",
        "df = df.rename(columns={'date': 'timestamp'})\n",
        "\n",
        "# Save to new CSV\n",
        "output_file = \"Enhets data - Varbergs boxningsklubb - RSRP.csv_corr.csv\"\n",
        "df.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"Saved as: {output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "23fdf4e6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved as: Enhets data - Katarinasstädtjänst Enhet Grind - Unlock_corr.csv\n",
            "Saved as: Enhets data - SMRTEC huvudEntre - Unlock_corr.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your CSV\n",
        "file_path = \"Enhets data - Katarinasstädtjänst Enhet Grind - Unlock.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Merge date1 + time1 into datetime1\n",
        "df['_timestamp'] = pd.to_datetime(\n",
        "    df['date1'].astype(str) + \" \" + df['time1'].astype(str),\n",
        "    errors='coerce'\n",
        ")\n",
        "\n",
        "# Merge date2 + time2 into datetime2\n",
        "df['_ack_timestamp'] = pd.to_datetime(\n",
        "    df['date2'].astype(str) + \" \" + df['time2'].astype(str),\n",
        "    errors='coerce'\n",
        ")\n",
        "\n",
        "# Drop original date/time columns\n",
        "df = df.drop(columns=['date1', 'time1', 'date2', 'time2'])\n",
        "\n",
        "# Reorder columns\n",
        "df = df[['  _id ', ' _uuid ', '_timestamp', 'rpc   ', '_ack_timestamp', '_ack_status']]\n",
        "\n",
        "# Save to new CSV\n",
        "output_file = \"Enhets data - Katarinasstädtjänst Enhet Grind - Unlock_corr.csv\"\n",
        "df.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"Saved as: {output_file}\")\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load your CSV\n",
        "file_path = \"Enhets data - SMRTEC huvudEntre - Unlock.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Merge date1 + time1 into datetime1\n",
        "df['_timestamp'] = pd.to_datetime(\n",
        "    df['date1'].astype(str) + \" \" + df['time1'].astype(str),\n",
        "    errors='coerce'\n",
        ")\n",
        "\n",
        "# Merge date2 + time2 into datetime2\n",
        "df['_ack_timestamp'] = pd.to_datetime(\n",
        "    df['date2'].astype(str) + \" \" + df['time2'].astype(str),\n",
        "    errors='coerce'\n",
        ")\n",
        "\n",
        "# Drop original date/time columns\n",
        "df = df.drop(columns=['date1', 'time1', 'date2', 'time2'])\n",
        "\n",
        "# Reorder columns\n",
        "df = df[['  _id ', ' _uuid ', '_timestamp', 'rpc   ', '_ack_timestamp', '_ack_status']]\n",
        "\n",
        "# Save to new CSV\n",
        "output_file = \"Enhets data - SMRTEC huvudEntre - Unlock_corr.csv\"\n",
        "df.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"Saved as: {output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "89b18338",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['  _id ', ' _uuid ', 'date1', 'time1', 'rpc   ', 'date2', 'time2', '_ack_status']\n"
          ]
        }
      ],
      "source": [
        "file_path = \"Enhets data - Katarinasstädtjänst Enhet Grind - Unlock.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "print(df.columns.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "e8e661eb",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load both CSVs\n",
        "rsrp = pd.read_csv(\"Enhets data - Katarinasstädtjänst Enhet Grind - RSRP_corr.csv\")\n",
        "unlock = pd.read_csv(\"Enhets data - Katarinasstädtjänst Enhet Grind - Unlock_corr.csv\")\n",
        "\n",
        "# Combine them vertically\n",
        "combined = pd.concat([rsrp, unlock], ignore_index=True)\n",
        "\n",
        "# Save result\n",
        "combined.to_csv(\"Enhets data - Katarinasstädtjänst Enhet Grind _combined.csv\", index=False)\n",
        "df = pd.read_csv (\"Enhets data - Katarinasstädtjänst Enhet Grind _combined.csv\")\n",
        "df.head()\n",
        "df.shape    \n",
        "\n",
        "# Load both CSVs\n",
        "rsrp = pd.read_csv(\"Enhets data - SMRTEC huvudEntre - RSRP.csv_corr.csv\")\n",
        "unlock = pd.read_csv(\"Enhets data - SMRTEC huvudEntre - Unlock_corr.csv\")\n",
        "\n",
        "# Combine them vertically\n",
        "combined = pd.concat([rsrp, unlock], ignore_index=True)\n",
        "\n",
        "# Save result\n",
        "combined.to_csv(\"Enhets data - SMRTEC huvudEntre_combined.csv\", index=False)\n",
        "   \n",
        "# Load both CSVs\n",
        "rsrp = pd.read_csv(\"Enhets data - Varbergs boxningsklubb - RSRP.csv_corr.csv\")\n",
        "unlock = pd.read_csv(\"Enhets data - Varbergs boxningsklubb - Unlock.csv\")\n",
        "\n",
        "# Combine them vertically\n",
        "combined = pd.concat([rsrp, unlock], ignore_index=True)\n",
        "\n",
        "# Save result\n",
        "combined.to_csv(\"Enhets data - Varbergs boxningsklubb_combined.csv\", index=False)\n",
        "   \n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "e5fb87f4",
      "metadata": {},
      "outputs": [
        {
          "ename": "PermissionError",
          "evalue": "[WinError 5] Åtkomst nekad: 'C:/Users/yulia'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[8], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m output_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/yulia/Desktop/LIA1_project/3_enheterna_output_folder/\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Folder to save updated CSVs\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Create output directory if it doesn't exist\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Get all CSV files in the input folder\u001b[39;00m\n\u001b[0;32m     13\u001b[0m csv_files \u001b[38;5;241m=\u001b[39m glob(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(input_folder, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*.csv\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
            "File \u001b[1;32m<frozen os>:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[1;34m(name, mode, exist_ok)\u001b[0m\n",
            "File \u001b[1;32m<frozen os>:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[1;34m(name, mode, exist_ok)\u001b[0m\n",
            "File \u001b[1;32m<frozen os>:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[1;34m(name, mode, exist_ok)\u001b[0m\n",
            "File \u001b[1;32m<frozen os>:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[1;34m(name, mode, exist_ok)\u001b[0m\n",
            "\u001b[1;31mPermissionError\u001b[0m: [WinError 5] Åtkomst nekad: 'C:/Users/yulia'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from glob import glob\n",
        "\n",
        "# Set input and output directories\n",
        "input_folder = 'C:/Users/yulia/Desktop/LIA1_project/3_enheterna_input_folder/'   # Replace with your folder path\n",
        "output_folder = 'C:/Users/yulia/Desktop/LIA1_project/3_enheterna_output_folder/'  # Folder to save updated CSVs\n",
        "\n",
        "# Create output directory if it doesn't exist\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Get all CSV files in the input folder\n",
        "csv_files = glob(os.path.join(input_folder, '*.csv'))\n",
        "\n",
        "# Process each file\n",
        "for file_path in csv_files:\n",
        "    try:\n",
        "        # Read CSV\n",
        "        df = pd.read_csv(file_path)\n",
        "        df.columns = df.columns.str.strip()\n",
        "\n",
        "        # Convert to datetime\n",
        "        df['_timestamp'] = pd.to_datetime(df['_timestamp'], errors='coerce')\n",
        "        df['_ack_timestamp'] = pd.to_datetime(df['_ack_timestamp'], errors='coerce')\n",
        "\n",
        "        # Calculate response time\n",
        "        df['response_time_seconds'] = (\n",
        "            df['_ack_timestamp'] - df['_timestamp']\n",
        "        ).dt.total_seconds()\n",
        "\n",
        "        # Build output file path\n",
        "        filename = os.path.basename(file_path)\n",
        "        output_path = os.path.join(output_folder, filename)\n",
        "\n",
        "        # Save to output file\n",
        "        df.to_csv(output_path, index=False)\n",
        "\n",
        "        print(f\"Processed: {filename}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to process {file_path}: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efb1e9f5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Response time added. Saved to: C:/Users/yulia/Desktop/LIA1_project/3_enheterna_input_folder/Enhets data - Katarinasstädtjänst Enhet Grind _combined_with_response_time.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file\n",
        "input_file = 'C:/Users/yulia/Desktop/LIA1_project/3_enheterna_input_folder/Enhets data - Katarinasstädtjänst Enhet Grind _combined.csv'  # Replace with your actual file path\n",
        "output_file = 'C:/Users/yulia/Desktop/LIA1_project/3_enheterna_input_folder/Enhets data - Katarinasstädtjänst Enhet Grind _combined_with_response_time.csv'  # Output file\n",
        "\n",
        "# Read the CSV\n",
        "df = pd.read_csv(input_file)\n",
        "\n",
        "# Clean column names\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "# Convert timestamp columns to datetime\n",
        "df['_timestamp'] = pd.to_datetime(df['_timestamp'], errors='coerce')\n",
        "df['_ack_timestamp'] = pd.to_datetime(df['_ack_timestamp'], errors='coerce')\n",
        "\n",
        "# Calculate response time in seconds\n",
        "df['response_time_seconds'] = (\n",
        "    df['_ack_timestamp'] - df['_timestamp']\n",
        ").dt.total_seconds()\n",
        "\n",
        "# Save to a new CSV file\n",
        "df.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"Response time added. Saved to: {output_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "535bf99c",
      "metadata": {},
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'C:/Users/yulia/Desktop/LIA1_project/3_enheterna_output_folder/Enhets data - SMRTEC huvudEntre_combined.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# --- Load Data ---\u001b[39;00m\n\u001b[0;32m     10\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/yulia/Desktop/LIA1_project/3_enheterna_output_folder/Enhets data - SMRTEC huvudEntre_combined.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# adjust path if needed\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# --- Data Cleaning ---\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Focus on RPC entries that have response times\u001b[39;00m\n\u001b[0;32m     15\u001b[0m df_rpcs \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponse_time_seconds\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnotna()]\u001b[38;5;241m.\u001b[39mcopy()\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/yulia/Desktop/LIA1_project/3_enheterna_output_folder/Enhets data - SMRTEC huvudEntre_combined.csv'"
          ]
        }
      ],
      "source": [
        "# ==============================================\n",
        "# 📈 Response Time Distribution Analysis\n",
        "# ==============================================\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# --- Load Data ---\n",
        "file_path = \"C:/Users/yulia/Desktop/LIA1_project/3_enheterna_output_folder/Enhets data - SMRTEC huvudEntre_combined.csv\"  # adjust path if needed\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# --- Data Cleaning ---\n",
        "# Focus on RPC entries that have response times\n",
        "df_rpcs = df[df['response_time_seconds'].notna()].copy()\n",
        "\n",
        "# Convert response_time_seconds to numeric (if not already)\n",
        "df_rpcs['response_time_seconds'] = pd.to_numeric(df_rpcs['response_time_seconds'], errors='coerce')\n",
        "\n",
        "# Drop invalid or zero values\n",
        "df_rpcs = df_rpcs[df_rpcs['response_time_seconds'] > 0]\n",
        "\n",
        "# --- Summary Statistics ---\n",
        "summary = df_rpcs['response_time_seconds'].describe()\n",
        "print(\"\\n===== RESPONSE TIME SUMMARY =====\")\n",
        "print(summary)\n",
        "\n",
        "# --- Plot Distribution ---\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(df_rpcs['response_time_seconds'], bins=30, kde=True)\n",
        "plt.title('Response Time Distribution')\n",
        "plt.xlabel('Response Time (seconds)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# --- Optional: Boxplot for Outliers ---\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.boxplot(x=df_rpcs['response_time_seconds'])\n",
        "plt.title('Response Time Boxplot (Outlier Detection)')\n",
        "plt.xlabel('Response Time (seconds)')\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b2df9b2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['_id', '_uuid', 'timestamp', 'just_booted', 'reset_reason', 'uptime', 'fw_version', 'modem_fw_version', 'rsrp', '_timestamp', 'rpc', '_ack_timestamp', '_ack_status', 'response_time_seconds']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(1466, 14)"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "file_path = \"C:/Users/yulia/Desktop/LIA1_project/3_enheterna_output_folder/Enhets data - SMRTEC huvudEntre_combined.csv\"  # adjust path if needed\n",
        "df = pd.read_csv(file_path)\n",
        "print(df.columns.tolist())\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11382ce6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['_id', '_uuid', 'timestamp', 'just_booted', 'reset_reason', 'uptime', 'fw_version', 'modem_fw_version', 'rsrp', '_timestamp', 'rpc', '_ack_timestamp', '_ack_status', 'response_time_seconds']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(2687, 14)"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "file_path = \"C:/Users/yulia/Desktop/LIA1_project/3_enheterna_output_folder/Enhets data - Katarinasstädtjänst Enhet Grind _combined.csv\"  # adjust path if needed\n",
        "df = pd.read_csv(file_path)\n",
        "print(df.columns.tolist())\n",
        "df.shape "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e525ed0",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2f16026",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['_id', '_uuid', 'timestamp', 'just_booted', 'reset_reason', 'uptime', 'fw_version', 'modem_fw_version', 'rsrp', '_timestamp', 'rpc', '_ack_timestamp', '_ack_status', 'response_time_seconds']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(1466, 14)"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "file_path = \"C:/Users/yulia/Desktop/LIA1_project/3_enheterna_output_folder/Enhets data - Varbergs boxningsklubb_combined.csv\"  # adjust path if needed\n",
        "df = pd.read_csv(file_path)\n",
        "print(df.columns.tolist())\n",
        "df.shape\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
