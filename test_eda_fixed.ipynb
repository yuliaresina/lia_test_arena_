{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f010dea6",
      "metadata": {},
      "source": [
        "# **Priliminary data analysis of Arena HUBs**\n",
        "\n",
        "## Data are the logs from a remote Arena system, access control system that unlocks doors.\n",
        "\n",
        "Initial files contain the following records:\n",
        "\n",
        "*_id ‚Äì  record ID\n",
        "\n",
        "_uuid ‚Äì device identifier, from hardware ( IMEI-like value).\n",
        "\n",
        "_timestamp ‚Äì event time (UTC)\n",
        "\n",
        "rpc ‚Äì the type of action/event (always ‚Äúunlock‚Äù in the file).\n",
        "\n",
        "_ack_timestamp ‚Äì acknowledgement time (when the system confirmed the event).\n",
        "\n",
        "_ack_status ‚Äì acknowledgement result (0 means success, empty means not acknowledged).*\n",
        "\n",
        "Initial second dataset contain diagnostic telemetry and metadata \n",
        "It‚Äôs recording resets, uptime, firmware versions, and network signal strength.\n",
        "\n",
        "*_id ‚Äì unique row identifier \n",
        "\n",
        "_uuid ‚Äì device identifier \n",
        "\n",
        "timestamp ‚Äì when the record was captured\n",
        "\n",
        "just_booted ‚Äì t means the device had just restarted when the log was recorded.\n",
        "\n",
        "reset_reason ‚Äì numeric code for why the device reset (e.g., 0, 2, 16 ‚Ä¶ probably mapped to watchdog, power cycle, etc.).\n",
        "\n",
        "uptime ‚Äì how many seconds the device had been running before the log.\n",
        "\n",
        "fw_version ‚Äì firmware version running on the device.\n",
        "\n",
        "modem_fw_version ‚Äì modem firmware version \n",
        "\n",
        "rsrp ‚Äì signal strength (Reference Signal Received Power, typical for LTE/5G modules).\n",
        "*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ea90c4ed",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load Excel\n",
        "df = pd.read_excel(\"Enhets data.xlsx\")\n",
        "\n",
        "# Combine date + time into a single datetime column\n",
        "df['timestamp'] = pd.to_datetime(\n",
        "    df['date'].astype(str) + \" \" + df['time'].astype(str),\n",
        "    errors='coerce'\n",
        ")\n",
        "\n",
        "# Keep only the combined column\n",
        "df = df[['timestamp']]\n",
        "\n",
        "# Save to CSV\n",
        "df.to_csv(\"enhets_datetime.csv\", index=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "1598d441",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1045, 1)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv (\"enhets_datetime.csv\")\n",
        "df.head()\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "8f5c4b91",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved as: Enhets data - Katarinasst√§dtj√§nst Enhet Grind - RSRP_corr.csv\n",
            "Saved as: Enhets data - SMRTEC huvudEntre - RSRP.csv_corr.csv\n",
            "Saved as: Enhets data - Varbergs boxningsklubb - RSRP.csv_corr.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your CSV\n",
        "file_path = \"Enhets data - Katarinasst√§dtj√§nst Enhet Grind - RSRP.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Replace 'date' column with merged datetime\n",
        "df['date'] = pd.to_datetime(\n",
        "    df['date'].astype(str) + \" \" + df['time'].astype(str),\n",
        "    errors='coerce'\n",
        ")\n",
        "\n",
        "# Drop the separate 'time' column\n",
        "df = df.drop(columns=['time'])\n",
        "\n",
        "# Optionally rename 'date' ‚Üí 'datetime'\n",
        "df = df.rename(columns={'date': 'timestamp'})\n",
        "\n",
        "# Save to new CSV\n",
        "output_file = \"Enhets data - Katarinasst√§dtj√§nst Enhet Grind - RSRP_corr.csv\"\n",
        "df.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"Saved as: {output_file}\")\n",
        "\n",
        "# Load your CSV\n",
        "file_path = \"Enhets data - SMRTEC huvudEntre - RSRP.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Replace 'date' column with merged datetime\n",
        "df['date'] = pd.to_datetime(\n",
        "    df['date'].astype(str) + \" \" + df['time'].astype(str),\n",
        "    errors='coerce'\n",
        ")\n",
        "\n",
        "# Drop the separate 'time' column\n",
        "df = df.drop(columns=['time'])\n",
        "\n",
        "# Optionally rename 'date' ‚Üí 'datetime'\n",
        "df = df.rename(columns={'date': 'timestamp'})\n",
        "\n",
        "# Save to new CSV\n",
        "output_file = \"Enhets data - SMRTEC huvudEntre - RSRP.csv_corr.csv\"\n",
        "df.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"Saved as: {output_file}\")\n",
        "\n",
        "# Load your CSV\n",
        "file_path = \"Enhets data - Varbergs boxningsklubb - RSRP.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Replace 'date' column with merged datetime\n",
        "df['date'] = pd.to_datetime(\n",
        "    df['date'].astype(str) + \" \" + df['time'].astype(str),\n",
        "    errors='coerce'\n",
        ")\n",
        "\n",
        "# Drop the separate 'time' column\n",
        "df = df.drop(columns=['time'])\n",
        "\n",
        "# Optionally rename 'date' ‚Üí 'datetime'\n",
        "df = df.rename(columns={'date': 'timestamp'})\n",
        "\n",
        "# Save to new CSV\n",
        "output_file = \"Enhets data - Varbergs boxningsklubb - RSRP.csv_corr.csv\"\n",
        "df.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"Saved as: {output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "23fdf4e6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved as: Enhets data - Katarinasst√§dtj√§nst Enhet Grind - Unlock_corr.csv\n",
            "Saved as: Enhets data - SMRTEC huvudEntre - Unlock_corr.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your CSV\n",
        "file_path = \"Enhets data - Katarinasst√§dtj√§nst Enhet Grind - Unlock.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Merge date1 + time1 into datetime1\n",
        "df['_timestamp'] = pd.to_datetime(\n",
        "    df['date1'].astype(str) + \" \" + df['time1'].astype(str),\n",
        "    errors='coerce'\n",
        ")\n",
        "\n",
        "# Merge date2 + time2 into datetime2\n",
        "df['_ack_timestamp'] = pd.to_datetime(\n",
        "    df['date2'].astype(str) + \" \" + df['time2'].astype(str),\n",
        "    errors='coerce'\n",
        ")\n",
        "\n",
        "# Drop original date/time columns\n",
        "df = df.drop(columns=['date1', 'time1', 'date2', 'time2'])\n",
        "\n",
        "# Reorder columns\n",
        "df = df[['  _id ', ' _uuid ', '_timestamp', 'rpc   ', '_ack_timestamp', '_ack_status']]\n",
        "\n",
        "# Save to new CSV\n",
        "output_file = \"Enhets data - Katarinasst√§dtj√§nst Enhet Grind - Unlock_corr.csv\"\n",
        "df.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"Saved as: {output_file}\")\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load your CSV\n",
        "file_path = \"Enhets data - SMRTEC huvudEntre - Unlock.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Merge date1 + time1 into datetime1\n",
        "df['_timestamp'] = pd.to_datetime(\n",
        "    df['date1'].astype(str) + \" \" + df['time1'].astype(str),\n",
        "    errors='coerce'\n",
        ")\n",
        "\n",
        "# Merge date2 + time2 into datetime2\n",
        "df['_ack_timestamp'] = pd.to_datetime(\n",
        "    df['date2'].astype(str) + \" \" + df['time2'].astype(str),\n",
        "    errors='coerce'\n",
        ")\n",
        "\n",
        "# Drop original date/time columns\n",
        "df = df.drop(columns=['date1', 'time1', 'date2', 'time2'])\n",
        "\n",
        "# Reorder columns\n",
        "df = df[['  _id ', ' _uuid ', '_timestamp', 'rpc   ', '_ack_timestamp', '_ack_status']]\n",
        "\n",
        "# Save to new CSV\n",
        "output_file = \"Enhets data - SMRTEC huvudEntre - Unlock_corr.csv\"\n",
        "df.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"Saved as: {output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "89b18338",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['  _id ', ' _uuid ', 'date1', 'time1', 'rpc   ', 'date2', 'time2', '_ack_status']\n"
          ]
        }
      ],
      "source": [
        "file_path = \"Enhets data - Katarinasst√§dtj√§nst Enhet Grind - Unlock.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "print(df.columns.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "e8e661eb",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load both CSVs\n",
        "rsrp = pd.read_csv(\"Enhets data - Katarinasst√§dtj√§nst Enhet Grind - RSRP_corr.csv\")\n",
        "unlock = pd.read_csv(\"Enhets data - Katarinasst√§dtj√§nst Enhet Grind - Unlock_corr.csv\")\n",
        "\n",
        "# Combine them vertically\n",
        "combined = pd.concat([rsrp, unlock], ignore_index=True)\n",
        "\n",
        "# Save result\n",
        "combined.to_csv(\"Enhets data - Katarinasst√§dtj√§nst Enhet Grind _combined.csv\", index=False)\n",
        "df = pd.read_csv (\"Enhets data - Katarinasst√§dtj√§nst Enhet Grind _combined.csv\")\n",
        "df.head()\n",
        "df.shape    \n",
        "\n",
        "# Load both CSVs\n",
        "rsrp = pd.read_csv(\"Enhets data - SMRTEC huvudEntre - RSRP.csv_corr.csv\")\n",
        "unlock = pd.read_csv(\"Enhets data - SMRTEC huvudEntre - Unlock_corr.csv\")\n",
        "\n",
        "# Combine them vertically\n",
        "combined = pd.concat([rsrp, unlock], ignore_index=True)\n",
        "\n",
        "# Save result\n",
        "combined.to_csv(\"Enhets data - SMRTEC huvudEntre_combined.csv\", index=False)\n",
        "   \n",
        "# Load both CSVs\n",
        "rsrp = pd.read_csv(\"Enhets data - Varbergs boxningsklubb - RSRP.csv_corr.csv\")\n",
        "unlock = pd.read_csv(\"Enhets data - Varbergs boxningsklubb - Unlock.csv\")\n",
        "\n",
        "# Combine them vertically\n",
        "combined = pd.concat([rsrp, unlock], ignore_index=True)\n",
        "\n",
        "# Save result\n",
        "combined.to_csv(\"Enhets data - Varbergs boxningsklubb_combined.csv\", index=False)\n",
        "   \n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "e5fb87f4",
      "metadata": {},
      "outputs": [
        {
          "ename": "PermissionError",
          "evalue": "[WinError 5] √Ötkomst nekad: 'C:/Users/yulia'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[8], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m output_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/yulia/Desktop/LIA1_project/3_enheterna_output_folder/\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Folder to save updated CSVs\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Create output directory if it doesn't exist\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Get all CSV files in the input folder\u001b[39;00m\n\u001b[0;32m     13\u001b[0m csv_files \u001b[38;5;241m=\u001b[39m glob(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(input_folder, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*.csv\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
            "File \u001b[1;32m<frozen os>:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[1;34m(name, mode, exist_ok)\u001b[0m\n",
            "File \u001b[1;32m<frozen os>:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[1;34m(name, mode, exist_ok)\u001b[0m\n",
            "File \u001b[1;32m<frozen os>:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[1;34m(name, mode, exist_ok)\u001b[0m\n",
            "File \u001b[1;32m<frozen os>:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[1;34m(name, mode, exist_ok)\u001b[0m\n",
            "\u001b[1;31mPermissionError\u001b[0m: [WinError 5] √Ötkomst nekad: 'C:/Users/yulia'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from glob import glob\n",
        "\n",
        "# Set input and output directories\n",
        "input_folder = 'C:/Users/yulia/Desktop/LIA1_project/3_enheterna_input_folder/'   # Replace with your folder path\n",
        "output_folder = 'C:/Users/yulia/Desktop/LIA1_project/3_enheterna_output_folder/'  # Folder to save updated CSVs\n",
        "\n",
        "# Create output directory if it doesn't exist\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Get all CSV files in the input folder\n",
        "csv_files = glob(os.path.join(input_folder, '*.csv'))\n",
        "\n",
        "# Process each file\n",
        "for file_path in csv_files:\n",
        "    try:\n",
        "        # Read CSV\n",
        "        df = pd.read_csv(file_path)\n",
        "        df.columns = df.columns.str.strip()\n",
        "\n",
        "        # Convert to datetime\n",
        "        df['_timestamp'] = pd.to_datetime(df['_timestamp'], errors='coerce')\n",
        "        df['_ack_timestamp'] = pd.to_datetime(df['_ack_timestamp'], errors='coerce')\n",
        "\n",
        "        # Calculate response time\n",
        "        df['response_time_seconds'] = (\n",
        "            df['_ack_timestamp'] - df['_timestamp']\n",
        "        ).dt.total_seconds()\n",
        "\n",
        "        # Build output file path\n",
        "        filename = os.path.basename(file_path)\n",
        "        output_path = os.path.join(output_folder, filename)\n",
        "\n",
        "        # Save to output file\n",
        "        df.to_csv(output_path, index=False)\n",
        "\n",
        "        print(f\"Processed: {filename}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to process {file_path}: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efb1e9f5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Response time added. Saved to: C:/Users/yulia/Desktop/LIA1_project/3_enheterna_input_folder/Enhets data - Katarinasst√§dtj√§nst Enhet Grind _combined_with_response_time.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file\n",
        "input_file = 'C:/Users/yulia/Desktop/LIA1_project/3_enheterna_input_folder/Enhets data - Katarinasst√§dtj√§nst Enhet Grind _combined.csv'  # Replace with your actual file path\n",
        "output_file = 'C:/Users/yulia/Desktop/LIA1_project/3_enheterna_input_folder/Enhets data - Katarinasst√§dtj√§nst Enhet Grind _combined_with_response_time.csv'  # Output file\n",
        "\n",
        "# Read the CSV\n",
        "df = pd.read_csv(input_file)\n",
        "\n",
        "# Clean column names\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "# Convert timestamp columns to datetime\n",
        "df['_timestamp'] = pd.to_datetime(df['_timestamp'], errors='coerce')\n",
        "df['_ack_timestamp'] = pd.to_datetime(df['_ack_timestamp'], errors='coerce')\n",
        "\n",
        "# Calculate response time in seconds\n",
        "df['response_time_seconds'] = (\n",
        "    df['_ack_timestamp'] - df['_timestamp']\n",
        ").dt.total_seconds()\n",
        "\n",
        "# Save to a new CSV file\n",
        "df.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"Response time added. Saved to: {output_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "535bf99c",
      "metadata": {},
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'C:/Users/yulia/Desktop/LIA1_project/3_enheterna_output_folder/Enhets data - SMRTEC huvudEntre_combined.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# --- Load Data ---\u001b[39;00m\n\u001b[0;32m     10\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/yulia/Desktop/LIA1_project/3_enheterna_output_folder/Enhets data - SMRTEC huvudEntre_combined.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# adjust path if needed\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# --- Data Cleaning ---\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Focus on RPC entries that have response times\u001b[39;00m\n\u001b[0;32m     15\u001b[0m df_rpcs \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponse_time_seconds\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnotna()]\u001b[38;5;241m.\u001b[39mcopy()\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/yulia/Desktop/LIA1_project/3_enheterna_output_folder/Enhets data - SMRTEC huvudEntre_combined.csv'"
          ]
        }
      ],
      "source": [
        "# ==============================================\n",
        "# üìà Response Time Distribution Analysis\n",
        "# ==============================================\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# --- Load Data ---\n",
        "file_path = \"C:/Users/yulia/Desktop/LIA1_project/3_enheterna_output_folder/Enhets data - SMRTEC huvudEntre_combined.csv\"  # adjust path if needed\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# --- Data Cleaning ---\n",
        "# Focus on RPC entries that have response times\n",
        "df_rpcs = df[df['response_time_seconds'].notna()].copy()\n",
        "\n",
        "# Convert response_time_seconds to numeric (if not already)\n",
        "df_rpcs['response_time_seconds'] = pd.to_numeric(df_rpcs['response_time_seconds'], errors='coerce')\n",
        "\n",
        "# Drop invalid or zero values\n",
        "df_rpcs = df_rpcs[df_rpcs['response_time_seconds'] > 0]\n",
        "\n",
        "# --- Summary Statistics ---\n",
        "summary = df_rpcs['response_time_seconds'].describe()\n",
        "print(\"\\n===== RESPONSE TIME SUMMARY =====\")\n",
        "print(summary)\n",
        "\n",
        "# --- Plot Distribution ---\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(df_rpcs['response_time_seconds'], bins=30, kde=True)\n",
        "plt.title('Response Time Distribution')\n",
        "plt.xlabel('Response Time (seconds)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# --- Optional: Boxplot for Outliers ---\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.boxplot(x=df_rpcs['response_time_seconds'])\n",
        "plt.title('Response Time Boxplot (Outlier Detection)')\n",
        "plt.xlabel('Response Time (seconds)')\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b2df9b2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['_id', '_uuid', 'timestamp', 'just_booted', 'reset_reason', 'uptime', 'fw_version', 'modem_fw_version', 'rsrp', '_timestamp', 'rpc', '_ack_timestamp', '_ack_status', 'response_time_seconds']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(1466, 14)"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "file_path = \"C:/Users/yulia/Desktop/LIA1_project/3_enheterna_output_folder/Enhets data - SMRTEC huvudEntre_combined.csv\"  # adjust path if needed\n",
        "df = pd.read_csv(file_path)\n",
        "print(df.columns.tolist())\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11382ce6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['_id', '_uuid', 'timestamp', 'just_booted', 'reset_reason', 'uptime', 'fw_version', 'modem_fw_version', 'rsrp', '_timestamp', 'rpc', '_ack_timestamp', '_ack_status', 'response_time_seconds']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(2687, 14)"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "file_path = \"C:/Users/yulia/Desktop/LIA1_project/3_enheterna_output_folder/Enhets data - Katarinasst√§dtj√§nst Enhet Grind _combined.csv\"  # adjust path if needed\n",
        "df = pd.read_csv(file_path)\n",
        "print(df.columns.tolist())\n",
        "df.shape "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e525ed0",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2f16026",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['_id', '_uuid', 'timestamp', 'just_booted', 'reset_reason', 'uptime', 'fw_version', 'modem_fw_version', 'rsrp', '_timestamp', 'rpc', '_ack_timestamp', '_ack_status', 'response_time_seconds']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(1466, 14)"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "file_path = \"C:/Users/yulia/Desktop/LIA1_project/3_enheterna_output_folder/Enhets data - Varbergs boxningsklubb_combined.csv\"  # adjust path if needed\n",
        "df = pd.read_csv(file_path)\n",
        "print(df.columns.tolist())\n",
        "df.shape\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
